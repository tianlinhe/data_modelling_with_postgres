{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Step-by-step data modelling locally</center>\n",
    "<center>OS: MacOS; Dependencies: postgresql, Python3 (pandas, ipython-sql, psycopg2), Jupyter Lab</center>\n",
    "\n",
    "## Set up the local enviroment\n",
    "Create a work folder locally containing the six template files. Data can be downloaded to local by\n",
    "1. Go the Workspace provided by Udacity\n",
    "2. Open the terminal in the work space, type: `zip -r output.zip data`\n",
    "    \n",
    "## Start PostgreSQL in MacOS via brew in terminal\n",
    "\n",
    "```zsh\n",
    "$ brew services start postgresql\n",
    "```\n",
    "\n",
    "## Create the default database `studentdb`\n",
    "```zsh\n",
    "$ createdb studentdb\n",
    "```\n",
    "\n",
    "You can check if `studentdb` exists via:\n",
    "1. login with default user `postgres`\n",
    "2. display all databases by `\\l`\n",
    "\n",
    "```zsh\n",
    "$ psql postgres\n",
    "postgres=# \\l\n",
    "```\n",
    "\n",
    "<left><img src=\"img/create_studentdb.png\" width=\"600\"></left>\n",
    "\n",
    "## Read and process a single file using `etl.ipynb`\n",
    "`etl.ipynb` allows us to test queries in 1) `sql_queries.py` and 2) `create_tables.py`.\n",
    "To check if we successfully created the tables:\n",
    "* Method 1: via `ipython-sql`\n",
    "    1. Install `ipython-sql` by running `pip install ipython-sql` in terminal\n",
    "    2. Run all cells in `test.ipynb`\n",
    "    * reset path `%sql postgresql://student:student@127.0.0.1/sparkifydb` to `%sql postgresql://hetianlin:hetianlin@localhost/sparkifydb`\n",
    "    \n",
    "* Method 2: via psql in terminal\n",
    "    1. Go to `sparkifydb`\n",
    "    2. List all tables in `sparkifydb` by `\\dt`\n",
    "<img src=\"img/check_sparkifydb.png\" width=\"600\">\n",
    "\n",
    "    3. For each table_name, implemete the `SELECT * FROM table_name LIMIT 5;` commands\n",
    "    4. Quit `sparkifydb` by `\\q`\n",
    "    \n",
    "## Build the ETL peptide using `etl.py`\n",
    "`etl.py` allows us to develop ETL processes for all the files in the dataset. Remember to rerun `create_tables.py` to reset the tables before each time you run this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 files found in data/song_data\n",
      "1/71 files processed.\n",
      "2/71 files processed.\n",
      "3/71 files processed.\n",
      "4/71 files processed.\n",
      "5/71 files processed.\n",
      "6/71 files processed.\n",
      "7/71 files processed.\n",
      "8/71 files processed.\n",
      "9/71 files processed.\n",
      "10/71 files processed.\n",
      "11/71 files processed.\n",
      "12/71 files processed.\n",
      "13/71 files processed.\n",
      "14/71 files processed.\n",
      "15/71 files processed.\n",
      "16/71 files processed.\n",
      "17/71 files processed.\n",
      "18/71 files processed.\n",
      "19/71 files processed.\n",
      "20/71 files processed.\n",
      "21/71 files processed.\n",
      "22/71 files processed.\n",
      "23/71 files processed.\n",
      "24/71 files processed.\n",
      "25/71 files processed.\n",
      "26/71 files processed.\n",
      "27/71 files processed.\n",
      "28/71 files processed.\n",
      "29/71 files processed.\n",
      "30/71 files processed.\n",
      "31/71 files processed.\n",
      "32/71 files processed.\n",
      "33/71 files processed.\n",
      "34/71 files processed.\n",
      "35/71 files processed.\n",
      "36/71 files processed.\n",
      "37/71 files processed.\n",
      "38/71 files processed.\n",
      "39/71 files processed.\n",
      "40/71 files processed.\n",
      "41/71 files processed.\n",
      "42/71 files processed.\n",
      "43/71 files processed.\n",
      "44/71 files processed.\n",
      "45/71 files processed.\n",
      "46/71 files processed.\n",
      "47/71 files processed.\n",
      "48/71 files processed.\n",
      "49/71 files processed.\n",
      "50/71 files processed.\n",
      "51/71 files processed.\n",
      "52/71 files processed.\n",
      "53/71 files processed.\n",
      "54/71 files processed.\n",
      "55/71 files processed.\n",
      "56/71 files processed.\n",
      "57/71 files processed.\n",
      "58/71 files processed.\n",
      "59/71 files processed.\n",
      "60/71 files processed.\n",
      "61/71 files processed.\n",
      "62/71 files processed.\n",
      "63/71 files processed.\n",
      "64/71 files processed.\n",
      "65/71 files processed.\n",
      "66/71 files processed.\n",
      "67/71 files processed.\n",
      "68/71 files processed.\n",
      "69/71 files processed.\n",
      "70/71 files processed.\n",
      "71/71 files processed.\n",
      "30 files found in data/log_data\n",
      "1/30 files processed.\n",
      "2/30 files processed.\n",
      "3/30 files processed.\n",
      "4/30 files processed.\n",
      "5/30 files processed.\n",
      "6/30 files processed.\n",
      "7/30 files processed.\n",
      "8/30 files processed.\n",
      "9/30 files processed.\n",
      "10/30 files processed.\n",
      "11/30 files processed.\n",
      "12/30 files processed.\n",
      "13/30 files processed.\n",
      "14/30 files processed.\n",
      "15/30 files processed.\n",
      "16/30 files processed.\n",
      "17/30 files processed.\n",
      "18/30 files processed.\n",
      "19/30 files processed.\n",
      "20/30 files processed.\n",
      "21/30 files processed.\n",
      "22/30 files processed.\n",
      "23/30 files processed.\n",
      "24/30 files processed.\n",
      "25/30 files processed.\n",
      "26/30 files processed.\n",
      "27/30 files processed.\n",
      "28/30 files processed.\n",
      "29/30 files processed.\n",
      "30/30 files processed.\n"
     ]
    }
   ],
   "source": [
    "%run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
